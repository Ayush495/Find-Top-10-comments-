{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "read_comments=pd.read_csv('comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cashier is a young woman from Guatemala (l...</td>\n",
       "      <td>6826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That girl will work her ass off for that man. ...</td>\n",
       "      <td>3459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My uncle has a saying: \"A whipped horse will r...</td>\n",
       "      <td>3822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is your uncle's view on spurs?</td>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Champions</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Comments  Points\n",
       "0  The cashier is a young woman from Guatemala (l...    6826\n",
       "1  That girl will work her ass off for that man. ...    3459\n",
       "2  My uncle has a saying: \"A whipped horse will r...    3822\n",
       "3                What is your uncle's view on spurs?    1117\n",
       "4                                          Champions    1325"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cashier is a young woman from Guatemala (l...</td>\n",
       "      <td>6826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My uncle has a saying: \"A whipped horse will r...</td>\n",
       "      <td>3822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That girl will work her ass off for that man. ...</td>\n",
       "      <td>3459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>People like your uncle the world needs more of...</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What a dumb show to get your username from</td>\n",
       "      <td>1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If we forget about the politics of the situati...</td>\n",
       "      <td>1597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Champions</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is your uncle's view on spurs?</td>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I like pancakes.</td>\n",
       "      <td>1067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Emoposer is a reference to goth episode of Sou...</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comments  Points\n",
       "0   The cashier is a young woman from Guatemala (l...    6826\n",
       "2   My uncle has a saying: \"A whipped horse will r...    3822\n",
       "1   That girl will work her ass off for that man. ...    3459\n",
       "5   People like your uncle the world needs more of...    1900\n",
       "14         What a dumb show to get your username from    1720\n",
       "6   If we forget about the politics of the situati...    1597\n",
       "4                                           Champions    1325\n",
       "3                 What is your uncle's view on spurs?    1117\n",
       "12                                   I like pancakes.    1067\n",
       "13  Emoposer is a reference to goth episode of Sou...     928"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_comments.sort('Points',ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect =CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_train=[\"The cashier is a young woman from Guatemala (legally immigrated here 4 years ago) (17, I think), she looked genuinely scared lifeless. My uncle drove her home to make sure that jackass didn't try anything and worked her shift.\",\"My uncle has a saying: A whipped horse will run, a loved horse will jump.\",\"That girl will work her ass off for that man. He's gotten something he couldn't buy. Actual loyalty.\",\"People like your uncle, the world needs more of them.\",\"What a dumb show to get your username from.\",\"If we forget about the politics of the situation, it's a customer threatening an employee. That's something that should not be tolerated.\",\"Champions\",\"What is your uncle's view on spurs?\",\"I like pancakes.\",\"Emoposer is a reference to goth episode of South Park.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bag_words=vect.fit_transform(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x95 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 117 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0, 0, 2, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "        1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2,\n",
       "        0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 0, 2, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>17</th>\n",
       "      <th>about</th>\n",
       "      <th>actual</th>\n",
       "      <th>ago</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>anything</th>\n",
       "      <th>ass</th>\n",
       "      <th>be</th>\n",
       "      <th>buy</th>\n",
       "      <th>...</th>\n",
       "      <th>what</th>\n",
       "      <th>whipped</th>\n",
       "      <th>will</th>\n",
       "      <th>woman</th>\n",
       "      <th>work</th>\n",
       "      <th>worked</th>\n",
       "      <th>world</th>\n",
       "      <th>years</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   17  about  actual  ago  an  and  anything  ass  be  buy  ...   what  \\\n",
       "0   1      0       0    1   0    1         1    0   0    0  ...      0   \n",
       "1   0      0       0    0   0    0         0    0   0    0  ...      0   \n",
       "2   0      0       1    0   0    0         0    1   0    1  ...      0   \n",
       "3   0      0       0    0   0    0         0    0   0    0  ...      0   \n",
       "4   0      0       0    0   0    0         0    0   0    0  ...      1   \n",
       "5   0      1       0    0   1    0         0    0   1    0  ...      0   \n",
       "6   0      0       0    0   0    0         0    0   0    0  ...      0   \n",
       "7   0      0       0    0   0    0         0    0   0    0  ...      1   \n",
       "8   0      0       0    0   0    0         0    0   0    0  ...      0   \n",
       "9   0      0       0    0   0    0         0    0   0    0  ...      0   \n",
       "\n",
       "   whipped  will  woman  work  worked  world  years  young  your  \n",
       "0        0     0      1     0       1      0      1      1     0  \n",
       "1        1     2      0     0       0      0      0      0     0  \n",
       "2        0     1      0     1       0      0      0      0     0  \n",
       "3        0     0      0     0       0      1      0      0     1  \n",
       "4        0     0      0     0       0      0      0      0     1  \n",
       "5        0     0      0     0       0      0      0      0     0  \n",
       "6        0     0      0     0       0      0      0      0     0  \n",
       "7        0     0      0     0       0      0      0      0     1  \n",
       "8        0     0      0     0       0      0      0      0     0  \n",
       "9        0     0      0     0       0      0      0      0     0  \n",
       "\n",
       "[10 rows x 95 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bag_words.toarray(),columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n",
      "\tWord: her, TF-IDF: 0.0602\n",
      "\tWord: The, TF-IDF: 0.04024\n",
      "\tWord: lifeless, TF-IDF: 0.04024\n",
      "\tWord: make, TF-IDF: 0.04024\n",
      "\tWord: home, TF-IDF: 0.04024\n",
      "\tWord: try, TF-IDF: 0.04024\n",
      "\tWord: shift, TF-IDF: 0.04024\n",
      "\tWord: Guatemala, TF-IDF: 0.04024\n",
      "\tWord: cashier, TF-IDF: 0.04024\n",
      "\tWord: think, TF-IDF: 0.04024\n",
      "Top words in document 2\n",
      "\tWord: A, TF-IDF: 0.32189\n",
      "\tWord: horse, TF-IDF: 0.21459\n",
      "\tWord: will, TF-IDF: 0.16053\n",
      "\tWord: has, TF-IDF: 0.1073\n",
      "\tWord: whipped, TF-IDF: 0.1073\n",
      "\tWord: run, TF-IDF: 0.1073\n",
      "\tWord: saying, TF-IDF: 0.1073\n",
      "\tWord: loved, TF-IDF: 0.1073\n",
      "\tWord: jump, TF-IDF: 0.1073\n",
      "\tWord: a, TF-IDF: 0.10217\n",
      "Top words in document 3\n",
      "\tWord: he, TF-IDF: 0.16094\n",
      "\tWord: He, TF-IDF: 0.16094\n",
      "\tWord: That, TF-IDF: 0.1204\n",
      "\tWord: that, TF-IDF: 0.09163\n",
      "\tWord: for, TF-IDF: 0.08047\n",
      "\tWord: could, TF-IDF: 0.08047\n",
      "\tWord: buy, TF-IDF: 0.08047\n",
      "\tWord: off, TF-IDF: 0.08047\n",
      "\tWord: gotten, TF-IDF: 0.08047\n",
      "\tWord: work, TF-IDF: 0.08047\n",
      "Top words in document 4\n",
      "\tWord: more, TF-IDF: 0.16094\n",
      "\tWord: world, TF-IDF: 0.16094\n",
      "\tWord: People, TF-IDF: 0.16094\n",
      "\tWord: them, TF-IDF: 0.16094\n",
      "\tWord: needs, TF-IDF: 0.16094\n",
      "\tWord: like, TF-IDF: 0.1204\n",
      "\tWord: the, TF-IDF: 0.1204\n",
      "\tWord: of, TF-IDF: 0.09163\n",
      "\tWord: your, TF-IDF: 0.09163\n",
      "\tWord: uncle, TF-IDF: 0.06931\n",
      "Top words in document 5\n",
      "\tWord: show, TF-IDF: 0.17883\n",
      "\tWord: get, TF-IDF: 0.17883\n",
      "\tWord: username, TF-IDF: 0.17883\n",
      "\tWord: dumb, TF-IDF: 0.17883\n",
      "\tWord: from, TF-IDF: 0.13377\n",
      "\tWord: What, TF-IDF: 0.13377\n",
      "\tWord: your, TF-IDF: 0.10181\n",
      "\tWord: to, TF-IDF: 0.10181\n",
      "\tWord: a, TF-IDF: 0.05676\n",
      "Top words in document 6\n",
      "\tWord: the, TF-IDF: 0.10033\n",
      "\tWord: That, TF-IDF: 0.10033\n",
      "\tWord: 's, TF-IDF: 0.07636\n",
      "\tWord: that, TF-IDF: 0.07636\n",
      "\tWord: not, TF-IDF: 0.06706\n",
      "\tWord: employee, TF-IDF: 0.06706\n",
      "\tWord: tolerated, TF-IDF: 0.06706\n",
      "\tWord: should, TF-IDF: 0.06706\n",
      "\tWord: an, TF-IDF: 0.06706\n",
      "\tWord: customer, TF-IDF: 0.06706\n",
      "Top words in document 7\n",
      "\tWord: Champions, TF-IDF: 1.60944\n",
      "Top words in document 8\n",
      "\tWord: spurs, TF-IDF: 0.20118\n",
      "\tWord: on, TF-IDF: 0.20118\n",
      "\tWord: view, TF-IDF: 0.20118\n",
      "\tWord: What, TF-IDF: 0.1505\n",
      "\tWord: is, TF-IDF: 0.11454\n",
      "\tWord: your, TF-IDF: 0.11454\n",
      "\tWord: 's, TF-IDF: 0.11454\n",
      "\tWord: uncle, TF-IDF: 0.08664\n",
      "Top words in document 9\n",
      "\tWord: pancakes, TF-IDF: 0.53648\n",
      "\tWord: like, TF-IDF: 0.40132\n",
      "\tWord: I, TF-IDF: 0.40132\n",
      "Top words in document 10\n",
      "\tWord: reference, TF-IDF: 0.16094\n",
      "\tWord: goth, TF-IDF: 0.16094\n",
      "\tWord: Emoposer, TF-IDF: 0.16094\n",
      "\tWord: episode, TF-IDF: 0.16094\n",
      "\tWord: South, TF-IDF: 0.16094\n",
      "\tWord: Park, TF-IDF: 0.16094\n",
      "\tWord: is, TF-IDF: 0.09163\n",
      "\tWord: of, TF-IDF: 0.09163\n",
      "\tWord: to, TF-IDF: 0.09163\n",
      "\tWord: a, TF-IDF: 0.05108\n"
     ]
    }
   ],
   "source": [
    "document1 = tb(\"The cashier is a young woman from Guatemala (legally immigrated here 4 years ago) (17, I think), she looked genuinely scared lifeless. My uncle drove her home to make sure that jackass didn't try anything and worked her shift.\")\n",
    "document2 = tb(\"My uncle has a saying: A whipped horse will run, a loved horse will jump.\")\n",
    "document3 = tb(\"That girl will work her ass off for that man. He's gotten something he couldn't buy. Actual loyalty.\")\n",
    "document4 = tb(\"People like your uncle, the world needs more of them.\")\n",
    "document5 = tb(\"What a dumb show to get your username from.\")\n",
    "document6 = tb(\"If we forget about the politics of the situation, it's a customer threatening an employee. That's something that should not be tolerated.\")\n",
    "document7 = tb(\"Champions.\")\n",
    "document8 = tb(\"What is your uncle's view on spurs?\")\n",
    "document9 = tb(\"I like pancakes.\")\n",
    "document10 = tb(\"Emoposer is a reference to goth episode of South Park.\")\n",
    "               \n",
    "bloblist = [document1, document2, document3,document4,document5,document6,document7,document8,document9,document10]\n",
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:10]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import word_tokenize,Text,pos_tag\n",
    "def sentence_verification(sentence):\n",
    "    word_find=sentence\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(word_find)\n",
    "    filtered_sentence=[]\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "                     filtered_sentence.append(w)\n",
    "    #print (filtered_sentence)\n",
    "    text = Text(filtered_sentence)\n",
    "    tags = pos_tag(text)\n",
    "    #print (tags)\n",
    "    nouns = \"NN NNP NNS\".split()\n",
    "    verbs = \"VB VBD VBP VBG\".split()\n",
    "    for i in range(len(tags) -1):\n",
    "        if tags[i][1] in nouns:\n",
    "            print (tags[i][0],tags[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cashier NN\n",
      "woman NN\n",
      "Guatemala NNP\n",
      "years NNS\n",
      "lifeless NN\n",
      "uncle NN\n",
      "jackass NN\n",
      "anything NN\n",
      "shift NN\n",
      ".....................................................................................................\n",
      "uncle NN\n",
      "horse NN\n",
      "run NN\n",
      "horse NN\n",
      "jump NN\n",
      ".....................................................................................................\n",
      "girl NN\n",
      "work NN\n",
      "ass NN\n",
      "man NN\n",
      "something NN\n",
      "Actual NNP\n",
      "loyalty NN\n",
      ".....................................................................................................\n",
      "People NNS\n",
      "uncle NN\n",
      "world NN\n",
      "needs NNS\n",
      ".....................................................................................................\n",
      "show NN\n",
      "get NN\n",
      ".....................................................................................................\n",
      "politics NNS\n",
      "situation NN\n",
      "customer NN\n",
      "threatening NN\n",
      "employee NN\n",
      "something NN\n",
      ".....................................................................................................\n",
      ".....................................................................................................\n",
      "uncle NN\n",
      "view NN\n",
      "spurs NNS\n",
      ".....................................................................................................\n",
      "pancakes NNS\n",
      ".....................................................................................................\n",
      "Emoposer NNP\n",
      "reference NN\n",
      "goth NN\n",
      "episode NN\n",
      "South NNP\n",
      "Park NNP\n",
      ".....................................................................................................\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(simple_train)):\n",
    "    sentence_verification(simple_train[i])\n",
    "    print(\".....................................................................................................\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
