{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page = requests.get('https://www.reddit.com/r/AdviceAnimals/comments/5y54am/my_uncle_is_an_awesome_boss/')\n",
    "tree = html.fromstring(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = tree.xpath('//div[@class=\"md\"]/p/text()')\n",
    "#This will create a list of points \n",
    "points = tree.xpath('//span[@class=\"score unvoted\"]/@title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "int_points_array = [int(numeric_string) for numeric_string in points]\n",
    "a={'Comments':pd.Series(comments),'Points':pd.Series(int_points_array)}\n",
    "df=pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>This is a good fucking way to look at any poli...</td>\n",
       "      <td>7002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The customer isn't always right. I feel like t...</td>\n",
       "      <td>3982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Politicical views dont matter, country of orig...</td>\n",
       "      <td>3581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People like your uncle, the world needs more o...</td>\n",
       "      <td>2051.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>I would happily be your uncle's horse!</td>\n",
       "      <td>1720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If we forget about the politics of the situati...</td>\n",
       "      <td>1706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The saying</td>\n",
       "      <td>1365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Your uncle is legend. Thank you and your family</td>\n",
       "      <td>931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Let's not forget the politics of the situation...</td>\n",
       "      <td>923.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>You log out?</td>\n",
       "      <td>898.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comments  Points\n",
       "17  This is a good fucking way to look at any poli...  7002.0\n",
       "19  The customer isn't always right. I feel like t...  3982.0\n",
       "18  Politicical views dont matter, country of orig...  3581.0\n",
       "0   People like your uncle, the world needs more o...  2051.0\n",
       "60             I would happily be your uncle's horse!  1720.0\n",
       "1   If we forget about the politics of the situati...  1706.0\n",
       "20                                        The saying   1365.0\n",
       "59    Your uncle is legend. Thank you and your family   931.0\n",
       "2   Let's not forget the politics of the situation...   923.0\n",
       "96                                       You log out?   898.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted=df.sort('Points',ascending=False)[0:10]\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'This is a good fucking way to look at any political situation these days, strip it down to its basic form, and analys it there...',\n",
       "       \"The customer isn't always right. I feel like the only people who say that are past 2005 are customers or shitty managers.\",\n",
       "       'Politicical views dont matter, country of origin does not matter, throw all of that shit away, and think of the basic scenario as u stated \"employe threatened by a custommer\"',\n",
       "       'People like your uncle, the world needs more of them. ',\n",
       "       \"I would happily be your uncle's horse!\",\n",
       "       \"If we forget about the politics of the situation, it's a customer threatening an employee. That's something that should not be tolerated. \",\n",
       "       'The saying ', 'Your uncle is legend. Thank you and your family',\n",
       "       \"Let's not forget the politics of the situation. I'm an immigrant just like your uncle's employee, and I appreciate employers that stand up against hate speech. \",\n",
       "       'You log out?'], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_array=df_sorted['Comments'].values[0:10]\n",
    "comments_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect =CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_words=vect.fit_transform(comments_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Bag of words approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2005</th>\n",
       "      <th>about</th>\n",
       "      <th>against</th>\n",
       "      <th>all</th>\n",
       "      <th>always</th>\n",
       "      <th>an</th>\n",
       "      <th>analys</th>\n",
       "      <th>and</th>\n",
       "      <th>any</th>\n",
       "      <th>appreciate</th>\n",
       "      <th>...</th>\n",
       "      <th>uncle</th>\n",
       "      <th>up</th>\n",
       "      <th>views</th>\n",
       "      <th>way</th>\n",
       "      <th>we</th>\n",
       "      <th>who</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2005  about  against  all  always  an  analys  and  any  appreciate  ...   \\\n",
       "0     0      0        0    0       0   0       1    1    1           0  ...    \n",
       "1     1      0        0    0       1   0       0    0    0           0  ...    \n",
       "2     0      0        0    1       0   0       0    1    0           0  ...    \n",
       "3     0      0        0    0       0   0       0    0    0           0  ...    \n",
       "4     0      0        0    0       0   0       0    0    0           0  ...    \n",
       "5     0      1        0    0       0   1       0    0    0           0  ...    \n",
       "6     0      0        0    0       0   0       0    0    0           0  ...    \n",
       "7     0      0        0    0       0   0       0    1    0           0  ...    \n",
       "8     0      0        1    0       0   1       0    1    0           1  ...    \n",
       "9     0      0        0    0       0   0       0    0    0           0  ...    \n",
       "\n",
       "   uncle  up  views  way  we  who  world  would  you  your  \n",
       "0      0   0      0    1   0    0      0      0    0     0  \n",
       "1      0   0      0    0   0    1      0      0    0     0  \n",
       "2      0   0      1    0   0    0      0      0    0     0  \n",
       "3      1   0      0    0   0    0      1      0    0     1  \n",
       "4      1   0      0    0   0    0      0      1    0     1  \n",
       "5      0   0      0    0   1    0      0      0    0     0  \n",
       "6      0   0      0    0   0    0      0      0    0     0  \n",
       "7      1   0      0    0   0    0      0      0    1     2  \n",
       "8      1   1      0    0   0    0      0      0    0     1  \n",
       "9      0   0      0    0   0    0      0      0    1     0  \n",
       "\n",
       "[10 rows x 100 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(bag_words.toarray(),columns=vect.get_feature_names())\n",
    "#From this no conclusion can be drawn as words like (is,a,the will be repeated many times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TfIDF approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "document1=tb(comments_array[0])\n",
    "document2=tb(comments_array[1])\n",
    "document3=tb(comments_array[2])\n",
    "document4=tb(comments_array[3])\n",
    "document5=tb(comments_array[4])\n",
    "document6=tb(comments_array[5])\n",
    "document7=tb(comments_array[6])\n",
    "document8=tb(comments_array[7])\n",
    "document9=tb(comments_array[8])\n",
    "document10=tb(comments_array[9])\n",
    "bloblist = [document1, document2, document3,document4,document5,document6,document7,document8,document9,document10]\n",
    "arr1=[]\n",
    "for i, blob in enumerate(bloblist):\n",
    "    #print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:10]:\n",
    "        #print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))\n",
    "        arr1.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize the words ,removing stop words from it ,finding nouns in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import word_tokenize,Text,pos_tag\n",
    "arr2=[]\n",
    "def sentence_verification(sentence):\n",
    "    word_find=sentence\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(word_find)\n",
    "    filtered_sentence=[]\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "                     filtered_sentence.append(w)\n",
    "    #print (filtered_sentence)\n",
    "    text = Text(filtered_sentence)\n",
    "    tags = pos_tag(text)\n",
    "    #print (tags)\n",
    "    nouns = \"NN NNP NNS\".split()\n",
    "    verbs = \"VB VBD VBP VBG\".split()\n",
    "    for i in range(len(tags) -1):\n",
    "        if tags[i][1] in nouns:\n",
    "            #print (tags[i][0],tags[i][1])\n",
    "            arr2.append(tags[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(comments_array)):\n",
    "    sentence_verification(comments_array[i])\n",
    "    #print(\".....................................................................................................\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will take only those words which are in all the three approaches and that will be our final set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thank',\n",
       " 'speech',\n",
       " 'matter',\n",
       " 'form',\n",
       " 'world',\n",
       " 'People',\n",
       " 'something',\n",
       " 'uncle',\n",
       " 'horse',\n",
       " 'needs',\n",
       " 'employers',\n",
       " 'customers',\n",
       " 'country',\n",
       " 'threatening',\n",
       " 'legend',\n",
       " 'days',\n",
       " 'people']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(arr1) & set(arr2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
